{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE:  THIS NOTEBOOK WILL TAKE 5-10 MINUTES TO COMPLETE.\n",
    "\n",
    "# PLEASE BE PATIENT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Analyze Data Quality with SageMaker Processing Jobs and Spark\n",
    "\n",
    "Typically a machine learning (ML) process consists of few steps. First, gathering data with various ETL jobs, then pre-processing the data, featurizing the dataset by incorporating standard techniques or prior knowledge, and finally training an ML model using an algorithm.\n",
    "\n",
    "Often, distributed data processing frameworks such as Spark are used to process and analyze data sets in order to detect data quality issues and prepare them for model training.  \n",
    "\n",
    "In this notebook we'll use Amazon SageMaker Processing with a library called [**Deequ**](https://github.com/awslabs/deequ), and leverage the power of Spark with a managed SageMaker Processing Job to run our data processing workloads.\n",
    "\n",
    "Here are some great resources on Deequ: \n",
    "* Blog Post:  https://aws.amazon.com/blogs/big-data/test-data-quality-at-scale-with-deequ/\n",
    "* Research Paper:  https://assets.amazon.science/4a/75/57047bd343fabc46ec14b34cdb3b/towards-automated-data-quality-management-for-machine-learning.pdf\n",
    "\n",
    "![Deequ](./img/deequ.png)\n",
    "\n",
    "![Processing Job](./img/processing.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Customer Reviews Dataset\n",
    "\n",
    "https://s3.amazonaws.com/amazon-reviews-pds/readme.html\n",
    "\n",
    "### Dataset Columns:\n",
    "\n",
    "- `marketplace`: 2-letter country code (in this case all \"US\").\n",
    "- `customer_id`: Random identifier that can be used to aggregate reviews written by a single author.\n",
    "- `review_id`: A unique ID for the review.\n",
    "- `product_id`: The Amazon Standard Identification Number (ASIN).  `http://www.amazon.com/dp/<ASIN>` links to the product's detail page.\n",
    "- `product_parent`: The parent of that ASIN.  Multiple ASINs (color or format variations of the same product) can roll up into a single parent.\n",
    "- `product_title`: Title description of the product.\n",
    "- `product_category`: Broad product category that can be used to group reviews (in this case digital videos).\n",
    "- `star_rating`: The review's rating (1 to 5 stars).\n",
    "- `helpful_votes`: Number of helpful votes for the review.\n",
    "- `total_votes`: Number of total votes the review received.\n",
    "- `vine`: Was the review written as part of the [Vine](https://www.amazon.com/gp/vine/help) program?\n",
    "- `verified_purchase`: Was the review from a verified purchase?\n",
    "- `review_headline`: The title of the review itself.\n",
    "- `review_body`: The text of the review.\n",
    "- `review_date`: The date the review was written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r ingest_create_athena_table_tsv_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ingest_create_athena_table_tsv_passed\n",
    "except NameError:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] YOU HAVE TO RUN THE NOTEBOOKS IN THE INGEST FOLDER FIRST. You did not register the TSV Data.\")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(ingest_create_athena_table_tsv_passed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK]\n"
     ]
    }
   ],
   "source": [
    "if not ingest_create_athena_table_tsv_passed:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] YOU HAVE TO RUN THE NOTEBOOKS IN THE INGEST FOLDER FIRST. You did not register the TSV Data.\")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "else:\n",
    "    print(\"[OK]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Analysis Job using a SageMaker Processing Job with Spark\n",
    "Next, use the Amazon SageMaker Python SDK to submit a processing job. Use the Spark container that was just built with our Spark script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review the Spark preprocessing script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m unicode_literals\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mshutil\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mcsv\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msubprocess\u001b[39;49;00m\n",
      "\n",
      "subprocess.check_call([sys.executable, \u001b[33m\"\u001b[39;49;00m\u001b[33m-m\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mpip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minstall\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m--no-deps\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mpydeequ==0.1.5\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "subprocess.check_call([sys.executable, \u001b[33m\"\u001b[39;49;00m\u001b[33m-m\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mpip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minstall\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mpandas==1.1.4\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpyspark\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpyspark\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msql\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SparkSession\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpyspark\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msql\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtypes\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m StructField, StructType, StringType, IntegerType, DoubleType\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpyspark\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msql\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctions\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m *\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpydeequ\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36manalyzers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m *\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpydeequ\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mchecks\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m *\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpydeequ\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mverification\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m *\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpydeequ\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msuggestions\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m *\n",
      "\n",
      "\u001b[37m# PySpark Deequ GitHub Repo:  https://github.com/awslabs/python-deequ\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmain\u001b[39;49;00m():\n",
      "    args_iter = \u001b[36miter\u001b[39;49;00m(sys.argv[\u001b[34m1\u001b[39;49;00m:])\n",
      "    args = \u001b[36mdict\u001b[39;49;00m(\u001b[36mzip\u001b[39;49;00m(args_iter, args_iter))\n",
      "\n",
      "    \u001b[37m# Retrieve the args and replace 's3://' with 's3a://' (used by Spark)\u001b[39;49;00m\n",
      "    s3_input_data = args[\u001b[33m\"\u001b[39;49;00m\u001b[33ms3_input_data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m].replace(\u001b[33m\"\u001b[39;49;00m\u001b[33ms3://\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33ms3a://\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[36mprint\u001b[39;49;00m(s3_input_data)\n",
      "    s3_output_analyze_data = args[\u001b[33m\"\u001b[39;49;00m\u001b[33ms3_output_analyze_data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m].replace(\u001b[33m\"\u001b[39;49;00m\u001b[33ms3://\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33ms3a://\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[36mprint\u001b[39;49;00m(s3_output_analyze_data)\n",
      "\n",
      "    spark = SparkSession.builder.appName(\u001b[33m\"\u001b[39;49;00m\u001b[33mPySparkAmazonReviewsAnalyzer\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m).getOrCreate()\n",
      "\n",
      "    schema = StructType(\n",
      "        [\n",
      "            StructField(\u001b[33m\"\u001b[39;49;00m\u001b[33mmarketplace\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m),\n",
      "            StructField(\u001b[33m\"\u001b[39;49;00m\u001b[33mcustomer_id\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m),\n",
      "            StructField(\u001b[33m\"\u001b[39;49;00m\u001b[33mreview_id\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m),\n",
      "            StructField(\u001b[33m\"\u001b[39;49;00m\u001b[33mproduct_id\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m),\n",
      "            StructField(\u001b[33m\"\u001b[39;49;00m\u001b[33mproduct_parent\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m),\n",
      "            StructField(\u001b[33m\"\u001b[39;49;00m\u001b[33mproduct_title\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m),\n",
      "            StructField(\u001b[33m\"\u001b[39;49;00m\u001b[33mproduct_category\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m),\n",
      "            StructField(\u001b[33m\"\u001b[39;49;00m\u001b[33mstar_rating\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, IntegerType(), \u001b[34mTrue\u001b[39;49;00m),\n",
      "            StructField(\u001b[33m\"\u001b[39;49;00m\u001b[33mhelpful_votes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, IntegerType(), \u001b[34mTrue\u001b[39;49;00m),\n",
      "            StructField(\u001b[33m\"\u001b[39;49;00m\u001b[33mtotal_votes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, IntegerType(), \u001b[34mTrue\u001b[39;49;00m),\n",
      "            StructField(\u001b[33m\"\u001b[39;49;00m\u001b[33mvine\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m),\n",
      "            StructField(\u001b[33m\"\u001b[39;49;00m\u001b[33mverified_purchase\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m),\n",
      "            StructField(\u001b[33m\"\u001b[39;49;00m\u001b[33mreview_headline\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m),\n",
      "            StructField(\u001b[33m\"\u001b[39;49;00m\u001b[33mreview_body\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m),\n",
      "            StructField(\u001b[33m\"\u001b[39;49;00m\u001b[33mreview_date\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m),\n",
      "        ]\n",
      "    )\n",
      "\n",
      "    dataset = spark.read.csv(s3_input_data, header=\u001b[34mTrue\u001b[39;49;00m, schema=schema, sep=\u001b[33m\"\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, quote=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Calculate statistics on the dataset\u001b[39;49;00m\n",
      "    analysisResult = (\n",
      "        AnalysisRunner(spark)\n",
      "        .onData(dataset)\n",
      "        .addAnalyzer(Size())\n",
      "        .addAnalyzer(Completeness(\u001b[33m\"\u001b[39;49;00m\u001b[33mreview_id\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "        .addAnalyzer(ApproxCountDistinct(\u001b[33m\"\u001b[39;49;00m\u001b[33mreview_id\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "        .addAnalyzer(Mean(\u001b[33m\"\u001b[39;49;00m\u001b[33mstar_rating\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "        .addAnalyzer(Compliance(\u001b[33m\"\u001b[39;49;00m\u001b[33mtop star_rating\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mstar_rating >= 4.0\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "        .addAnalyzer(Correlation(\u001b[33m\"\u001b[39;49;00m\u001b[33mtotal_votes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mstar_rating\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "        .addAnalyzer(Correlation(\u001b[33m\"\u001b[39;49;00m\u001b[33mtotal_votes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mhelpful_votes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "        .run()\n",
      "    )\n",
      "\n",
      "    metrics = AnalyzerContext.successMetricsAsDataFrame(spark, analysisResult)\n",
      "    metrics.show(truncate=\u001b[34mFalse\u001b[39;49;00m)\n",
      "    metrics.repartition(\u001b[34m1\u001b[39;49;00m).write.format(\u001b[33m\"\u001b[39;49;00m\u001b[33mcsv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m).mode(\u001b[33m\"\u001b[39;49;00m\u001b[33moverwrite\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m).option(\u001b[33m\"\u001b[39;49;00m\u001b[33mheader\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[34mTrue\u001b[39;49;00m).option(\u001b[33m\"\u001b[39;49;00m\u001b[33msep\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m).save(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/dataset-metrics\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(s3_output_analyze_data)\n",
      "    )\n",
      "\n",
      "    \u001b[37m# Check data quality\u001b[39;49;00m\n",
      "    verificationResult = (\n",
      "        VerificationSuite(spark)\n",
      "        .onData(dataset)\n",
      "        .addCheck(\n",
      "            Check(spark, CheckLevel.Error, \u001b[33m\"\u001b[39;49;00m\u001b[33mReview Check\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "            .hasSize(\u001b[34mlambda\u001b[39;49;00m x: x >= \u001b[34m200000\u001b[39;49;00m)\n",
      "            .hasMin(\u001b[33m\"\u001b[39;49;00m\u001b[33mstar_rating\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[34mlambda\u001b[39;49;00m x: x == \u001b[34m1.0\u001b[39;49;00m)\n",
      "            .hasMax(\u001b[33m\"\u001b[39;49;00m\u001b[33mstar_rating\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[34mlambda\u001b[39;49;00m x: x == \u001b[34m5.0\u001b[39;49;00m)\n",
      "            .isComplete(\u001b[33m\"\u001b[39;49;00m\u001b[33mreview_id\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "            .isUnique(\u001b[33m\"\u001b[39;49;00m\u001b[33mreview_id\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "            .isComplete(\u001b[33m\"\u001b[39;49;00m\u001b[33mmarketplace\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "            .isContainedIn(\u001b[33m\"\u001b[39;49;00m\u001b[33mmarketplace\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[33m\"\u001b[39;49;00m\u001b[33mUS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mUK\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mDE\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mJP\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mFR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "        )\n",
      "        .run()\n",
      "    )\n",
      "\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mVerification Run Status: \u001b[39;49;00m\u001b[33m{verificationResult.status}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    resultsDataFrame = VerificationResult.checkResultsAsDataFrame(spark, verificationResult)\n",
      "    resultsDataFrame.show(truncate=\u001b[34mFalse\u001b[39;49;00m)\n",
      "    resultsDataFrame.repartition(\u001b[34m1\u001b[39;49;00m).write.format(\u001b[33m\"\u001b[39;49;00m\u001b[33mcsv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m).mode(\u001b[33m\"\u001b[39;49;00m\u001b[33moverwrite\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m).option(\u001b[33m\"\u001b[39;49;00m\u001b[33mheader\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[34mTrue\u001b[39;49;00m).option(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33msep\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "    ).save(\u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/constraint-checks\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(s3_output_analyze_data))\n",
      "\n",
      "    verificationSuccessMetricsDataFrame = VerificationResult.successMetricsAsDataFrame(spark, verificationResult)\n",
      "    verificationSuccessMetricsDataFrame.show(truncate=\u001b[34mFalse\u001b[39;49;00m)\n",
      "    verificationSuccessMetricsDataFrame.repartition(\u001b[34m1\u001b[39;49;00m).write.format(\u001b[33m\"\u001b[39;49;00m\u001b[33mcsv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m).mode(\u001b[33m\"\u001b[39;49;00m\u001b[33moverwrite\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m).option(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mheader\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[34mTrue\u001b[39;49;00m\n",
      "    ).option(\u001b[33m\"\u001b[39;49;00m\u001b[33msep\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m).save(\u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/success-metrics\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(s3_output_analyze_data))\n",
      "\n",
      "    \u001b[37m# Suggest new checks and constraints\u001b[39;49;00m\n",
      "    suggestionsResult = ConstraintSuggestionRunner(spark).onData(dataset).addConstraintRule(DEFAULT()).run()\n",
      "\n",
      "    suggestions = suggestionsResult[\u001b[33m\"\u001b[39;49;00m\u001b[33mconstraint_suggestions\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "    parallelizedSuggestions = spark.sparkContext.parallelize(suggestions)\n",
      "\n",
      "    suggestionsResultsDataFrame = spark.createDataFrame(parallelizedSuggestions)\n",
      "    suggestionsResultsDataFrame.show(truncate=\u001b[34mFalse\u001b[39;49;00m)\n",
      "    suggestionsResultsDataFrame.repartition(\u001b[34m1\u001b[39;49;00m).write.format(\u001b[33m\"\u001b[39;49;00m\u001b[33mcsv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m).mode(\u001b[33m\"\u001b[39;49;00m\u001b[33moverwrite\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m).option(\u001b[33m\"\u001b[39;49;00m\u001b[33mheader\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[34mTrue\u001b[39;49;00m).option(\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33msep\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "    ).save(\u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/constraint-suggestions\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(s3_output_analyze_data))\n",
      "\n",
      "\n",
      "\u001b[37m#    spark.stop()\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    main()\n"
     ]
    }
   ],
   "source": [
    "!pygmentize preprocess-deequ-pyspark.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.spark.processing import PySparkProcessor\n",
    "\n",
    "processor = PySparkProcessor(\n",
    "    base_job_name=\"spark-amazon-reviews-analyzer\",\n",
    "    role=role,\n",
    "    framework_version=\"2.4\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.r5.2xlarge\",\n",
    "    max_runtime_in_seconds=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-117859797117/amazon-reviews-pds/tsv/\n"
     ]
    }
   ],
   "source": [
    "s3_input_data = \"s3://{}/amazon-reviews-pds/tsv/\".format(bucket)\n",
    "print(s3_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-05 10:25:39   18997559 amazon_reviews_us_Digital_Software_v1_00.tsv.gz\n",
      "2021-04-05 10:25:40   27442648 amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz\n",
      "2021-04-05 10:25:41   12134676 amazon_reviews_us_Gift_Card_v1_00.tsv.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $s3_input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Output Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing job name:  amazon-reviews-spark-analyzer-2021-04-05-18-58-51\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "output_prefix = \"amazon-reviews-spark-analyzer-{}\".format(timestamp_prefix)\n",
    "processing_job_name = \"amazon-reviews-spark-analyzer-{}\".format(timestamp_prefix)\n",
    "\n",
    "print(\"Processing job name:  {}\".format(processing_job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-117859797117/amazon-reviews-spark-analyzer-2021-04-05-18-58-51/output\n"
     ]
    }
   ],
   "source": [
    "s3_output_analyze_data = \"s3://{}/{}/output\".format(bucket, output_prefix)\n",
    "\n",
    "print(s3_output_analyze_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the Spark Processing Job\n",
    "\n",
    "_Notes on Invoking from Lambda:_\n",
    "* However, if we use the boto3 SDK (ie. with a Lambda), we need to copy the `preprocess.py` file to S3 and specify the everything include --py-files, etc.\n",
    "* We would need to do the following before invoking the Lambda:\n",
    "     !aws s3 cp preprocess.py s3://<location>/sagemaker/spark-preprocess-reviews-demo/code/preprocess.py\n",
    "     !aws s3 cp preprocess.py s3://<location>/sagemaker/spark-preprocess-reviews-demo/py_files/preprocess.py\n",
    "* Then reference the s3://<location> above in the --py-files, etc.\n",
    "* See Lambda example code in this same project for more details.\n",
    "\n",
    "_Notes on not using ProcessingInput and Output:_\n",
    "* Since Spark natively reads/writes from/to S3 using s3a://, we can avoid the copy required by ProcessingInput and ProcessingOutput (FullyReplicated or ShardedByS3Key) and just specify the S3 input and output buckets/prefixes._\"\n",
    "* See https://github.com/awslabs/amazon-sagemaker-examples/issues/994 for issues related to using /opt/ml/processing/input/ and output/\n",
    "* If we use ProcessingInput, the data will be copied to each node (which we don't want in this case since Spark already handles this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  spark-amazon-reviews-analyzer-2021-04-05-18-58-53-826\n",
      "Inputs:  [{'InputName': 'jars', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-117859797117/spark-amazon-reviews-analyzer-2021-04-05-18-58-53-826/input/jars', 'LocalPath': '/opt/ml/processing/input/jars', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-117859797117/spark-amazon-reviews-analyzer-2021-04-05-18-58-53-826/input/code/preprocess-deequ-pyspark.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  []\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingOutput\n",
    "\n",
    "processor.run(\n",
    "    submit_app=\"preprocess-deequ-pyspark.py\",\n",
    "    submit_jars=[\"deequ-1.0.3-rc2.jar\"],\n",
    "    arguments=[\n",
    "        \"s3_input_data\",\n",
    "        s3_input_data,\n",
    "        \"s3_output_analyze_data\",\n",
    "        s3_output_analyze_data,\n",
    "    ],\n",
    "    logs=True,\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/processing-jobs/spark-amazon-reviews-analyzer-2021-04-05-18-58-53-826\">Processing Job</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "processing_job_name = processor.jobs[-1].describe()[\"ProcessingJobName\"]\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/processing-jobs/{}\">Processing Job</a></b>'.format(\n",
    "            region, processing_job_name\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#logStream:group=/aws/sagemaker/ProcessingJobs;prefix=spark-amazon-reviews-analyzer-2021-04-05-18-58-53-826;streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a> After a Few Minutes</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "processing_job_name = processor.jobs[-1].describe()[\"ProcessingJobName\"]\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/ProcessingJobs;prefix={};streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a> After a Few Minutes</b>'.format(\n",
    "            region, processing_job_name\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/sagemaker-us-east-1-117859797117/amazon-reviews-spark-analyzer-2021-04-05-18-58-51/?region=us-east-1&tab=overview\">S3 Output Data</a> After The Spark Job Has Completed</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "s3_job_output_prefix = output_prefix\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/{}/{}/?region={}&tab=overview\">S3 Output Data</a> After The Spark Job Has Completed</b>'.format(\n",
    "            bucket, s3_job_output_prefix, region\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitor the Processing Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ProcessingInputs': [{'InputName': 'jars', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-117859797117/spark-amazon-reviews-analyzer-2021-04-05-18-58-53-826/input/jars', 'LocalPath': '/opt/ml/processing/input/jars', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-117859797117/spark-amazon-reviews-analyzer-2021-04-05-18-58-53-826/input/code/preprocess-deequ-pyspark.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}], 'ProcessingJobName': 'spark-amazon-reviews-analyzer-2021-04-05-18-58-53-826', 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.r5.2xlarge', 'VolumeSizeInGB': 30}}, 'StoppingCondition': {'MaxRuntimeInSeconds': 300}, 'AppSpecification': {'ImageUri': '173754725891.dkr.ecr.us-east-1.amazonaws.com/sagemaker-spark-processing:2.4-cpu', 'ContainerEntrypoint': ['smspark-submit', '--jars', '/opt/ml/processing/input/jars', '/opt/ml/processing/input/code/preprocess-deequ-pyspark.py'], 'ContainerArguments': ['s3_input_data', 's3://sagemaker-us-east-1-117859797117/amazon-reviews-pds/tsv/', 's3_output_analyze_data', 's3://sagemaker-us-east-1-117859797117/amazon-reviews-spark-analyzer-2021-04-05-18-58-51/output']}, 'Environment': {}, 'RoleArn': 'arn:aws:iam::117859797117:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole', 'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:117859797117:processing-job/spark-amazon-reviews-analyzer-2021-04-05-18-58-53-826', 'ProcessingJobStatus': 'InProgress', 'LastModifiedTime': datetime.datetime(2021, 4, 5, 18, 58, 54, 892000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2021, 4, 5, 18, 58, 54, 383000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': '93581be0-241f-4f31-8842-2580bbb9761f', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '93581be0-241f-4f31-8842-2580bbb9761f', 'content-type': 'application/x-amz-json-1.1', 'content-length': '1962', 'date': 'Mon, 05 Apr 2021 18:58:58 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "running_processor = sagemaker.processing.ProcessingJob.from_processing_name(\n",
    "    processing_job_name=processing_job_name, sagemaker_session=sess\n",
    ")\n",
    "\n",
    "processing_job_description = running_processor.describe()\n",
    "\n",
    "print(processing_job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "running_processor.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Please Wait Until the ^^ Processing Job ^^ Completes Above._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the Processed Output \n",
    "\n",
    "## These are the quality checks on our dataset.\n",
    "\n",
    "## _The next cells will not work properly until the job completes above._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-05 19:03:38          0 amazon-reviews-spark-analyzer-2021-04-05-18-58-51/output/constraint-checks/_SUCCESS\n",
      "2021-04-05 19:03:38        773 amazon-reviews-spark-analyzer-2021-04-05-18-58-51/output/constraint-checks/part-00000-ab460e13-1ea8-4581-83c1-823fcfacac4c-c000.csv\n",
      "2021-04-05 19:03:58          0 amazon-reviews-spark-analyzer-2021-04-05-18-58-51/output/constraint-suggestions/_SUCCESS\n",
      "2021-04-05 19:03:57       8615 amazon-reviews-spark-analyzer-2021-04-05-18-58-51/output/constraint-suggestions/part-00000-18e2a409-1b57-4cab-845a-e528d976751b-c000.csv\n",
      "2021-04-05 19:03:30          0 amazon-reviews-spark-analyzer-2021-04-05-18-58-51/output/dataset-metrics/_SUCCESS\n",
      "2021-04-05 19:03:29        364 amazon-reviews-spark-analyzer-2021-04-05-18-58-51/output/dataset-metrics/part-00000-e7352a43-304a-4416-bebb-a13e30d70de1-c000.csv\n",
      "2021-04-05 19:03:40          0 amazon-reviews-spark-analyzer-2021-04-05-18-58-51/output/success-metrics/_SUCCESS\n",
      "2021-04-05 19:03:40        277 amazon-reviews-spark-analyzer-2021-04-05-18-58-51/output/success-metrics/part-00000-c4ead785-db3d-480f-bb04-6e6004054f88-c000.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls --recursive $s3_output_analyze_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy the Output from S3 to Local\n",
    "* dataset-metrics/\n",
    "* constraint-checks/\n",
    "* success-metrics/\n",
    "* constraint-suggestions/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-117859797117/amazon-reviews-spark-analyzer-2021-04-05-18-58-51/output/dataset-metrics/part-00000-e7352a43-304a-4416-bebb-a13e30d70de1-c000.csv to amazon-reviews-spark-analyzer/dataset-metrics/part-00000-e7352a43-304a-4416-bebb-a13e30d70de1-c000.csv\n",
      "download: s3://sagemaker-us-east-1-117859797117/amazon-reviews-spark-analyzer-2021-04-05-18-58-51/output/success-metrics/part-00000-c4ead785-db3d-480f-bb04-6e6004054f88-c000.csv to amazon-reviews-spark-analyzer/success-metrics/part-00000-c4ead785-db3d-480f-bb04-6e6004054f88-c000.csv\n",
      "download: s3://sagemaker-us-east-1-117859797117/amazon-reviews-spark-analyzer-2021-04-05-18-58-51/output/constraint-suggestions/part-00000-18e2a409-1b57-4cab-845a-e528d976751b-c000.csv to amazon-reviews-spark-analyzer/constraint-suggestions/part-00000-18e2a409-1b57-4cab-845a-e528d976751b-c000.csv\n",
      "download: s3://sagemaker-us-east-1-117859797117/amazon-reviews-spark-analyzer-2021-04-05-18-58-51/output/constraint-checks/part-00000-ab460e13-1ea8-4581-83c1-823fcfacac4c-c000.csv to amazon-reviews-spark-analyzer/constraint-checks/part-00000-ab460e13-1ea8-4581-83c1-823fcfacac4c-c000.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $s3_output_analyze_data ./amazon-reviews-spark-analyzer/ --exclude=\"*\" --include=\"*.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Constraint Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def load_dataset(path, sep, header):\n",
    "    data = pd.concat(\n",
    "        [pd.read_csv(f, sep=sep, header=header) for f in glob.glob(\"{}/*.csv\".format(path))], ignore_index=True\n",
    "    )\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>check</th>\n",
       "      <th>constraint</th>\n",
       "      <th>constraint_status</th>\n",
       "      <th>constraint_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Review Check</td>\n",
       "      <td>SizeConstraint(Size(None))</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Review Check</td>\n",
       "      <td>MinimumConstraint(Minimum(star_rating,None))</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Review Check</td>\n",
       "      <td>MaximumConstraint(Maximum(star_rating,None))</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Review Check</td>\n",
       "      <td>CompletenessConstraint(Completeness(review_id,...</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Review Check</td>\n",
       "      <td>UniquenessConstraint(Uniqueness(List(review_id...</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Review Check</td>\n",
       "      <td>CompletenessConstraint(Completeness(marketplac...</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Review Check</td>\n",
       "      <td>ComplianceConstraint(Compliance(marketplace co...</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          check                                         constraint  \\\n",
       "0  Review Check                         SizeConstraint(Size(None))   \n",
       "1  Review Check       MinimumConstraint(Minimum(star_rating,None))   \n",
       "2  Review Check       MaximumConstraint(Maximum(star_rating,None))   \n",
       "3  Review Check  CompletenessConstraint(Completeness(review_id,...   \n",
       "4  Review Check  UniquenessConstraint(Uniqueness(List(review_id...   \n",
       "5  Review Check  CompletenessConstraint(Completeness(marketplac...   \n",
       "6  Review Check  ComplianceConstraint(Compliance(marketplace co...   \n",
       "\n",
       "  constraint_status  constraint_message  \n",
       "0           Success                 NaN  \n",
       "1           Success                 NaN  \n",
       "2           Success                 NaN  \n",
       "3           Success                 NaN  \n",
       "4           Success                 NaN  \n",
       "5           Success                 NaN  \n",
       "6           Success                 NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_constraint_checks = load_dataset(path=\"./amazon-reviews-spark-analyzer/constraint-checks/\", sep=\"\\t\", header=0)\n",
    "df_constraint_checks[[\"check\", \"constraint\", \"constraint_status\", \"constraint_message\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Dataset Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>instance</th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Column</td>\n",
       "      <td>review_id</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Column</td>\n",
       "      <td>review_id</td>\n",
       "      <td>ApproxCountDistinct</td>\n",
       "      <td>381704.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mutlicolumn</td>\n",
       "      <td>total_votes,star_rating</td>\n",
       "      <td>Correlation</td>\n",
       "      <td>-0.086052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset</td>\n",
       "      <td>*</td>\n",
       "      <td>Size</td>\n",
       "      <td>396601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Column</td>\n",
       "      <td>star_rating</td>\n",
       "      <td>Mean</td>\n",
       "      <td>4.102493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Column</td>\n",
       "      <td>top star_rating</td>\n",
       "      <td>Compliance</td>\n",
       "      <td>0.765893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mutlicolumn</td>\n",
       "      <td>total_votes,helpful_votes</td>\n",
       "      <td>Correlation</td>\n",
       "      <td>0.985751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        entity                   instance                 name          value\n",
       "0       Column                  review_id         Completeness       1.000000\n",
       "1       Column                  review_id  ApproxCountDistinct  381704.000000\n",
       "2  Mutlicolumn    total_votes,star_rating          Correlation      -0.086052\n",
       "3      Dataset                          *                 Size  396601.000000\n",
       "4       Column                star_rating                 Mean       4.102493\n",
       "5       Column            top star_rating           Compliance       0.765893\n",
       "6  Mutlicolumn  total_votes,helpful_votes          Correlation       0.985751"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset_metrics = load_dataset(path=\"./amazon-reviews-spark-analyzer/dataset-metrics/\", sep=\"\\t\", header=0)\n",
    "df_dataset_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Success Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>instance</th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Column</td>\n",
       "      <td>review_id</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Column</td>\n",
       "      <td>review_id</td>\n",
       "      <td>Uniqueness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset</td>\n",
       "      <td>*</td>\n",
       "      <td>Size</td>\n",
       "      <td>396601.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Column</td>\n",
       "      <td>star_rating</td>\n",
       "      <td>Maximum</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Column</td>\n",
       "      <td>star_rating</td>\n",
       "      <td>Minimum</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Column</td>\n",
       "      <td>marketplace contained in US,UK,DE,JP,FR</td>\n",
       "      <td>Compliance</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Column</td>\n",
       "      <td>marketplace</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    entity                                 instance          name     value\n",
       "0   Column                                review_id  Completeness       1.0\n",
       "1   Column                                review_id    Uniqueness       1.0\n",
       "2  Dataset                                        *          Size  396601.0\n",
       "3   Column                              star_rating       Maximum       5.0\n",
       "4   Column                              star_rating       Minimum       1.0\n",
       "5   Column  marketplace contained in US,UK,DE,JP,FR    Compliance       1.0\n",
       "6   Column                              marketplace  Completeness       1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_success_metrics = load_dataset(path=\"./amazon-reviews-spark-analyzer/success-metrics/\", sep=\"\\t\", header=0)\n",
    "df_success_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Constraint Suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_for_constraint</th>\n",
       "      <th>column_name</th>\n",
       "      <th>constraint_name</th>\n",
       "      <th>current_value</th>\n",
       "      <th>description</th>\n",
       "      <th>rule_description</th>\n",
       "      <th>suggesting_rule</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.isComplete(\\review_id\\\")\"</td>\n",
       "      <td>review_id</td>\n",
       "      <td>CompletenessConstraint(Completeness(review_id,None))</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'review_id' is not null</td>\n",
       "      <td>If a column is complete in the sample, we suggest a NOT NULL constraint</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.isUnique(\\review_id\\\")\"</td>\n",
       "      <td>review_id</td>\n",
       "      <td>UniquenessConstraint(Uniqueness(List(review_id),None))</td>\n",
       "      <td>ApproxDistinctness: 0.9624383196209793</td>\n",
       "      <td>'review_id' is unique</td>\n",
       "      <td>If the ratio of approximate num distinct values in a column is close to the number of records (within the error of the HLL sketch), we suggest a UNIQUE constraint</td>\n",
       "      <td>UniqueIfApproximatelyUniqueRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.isComplete(\\customer_id\\\")\"</td>\n",
       "      <td>customer_id</td>\n",
       "      <td>CompletenessConstraint(Completeness(customer_id,None))</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'customer_id' is not null</td>\n",
       "      <td>If a column is complete in the sample, we suggest a NOT NULL constraint</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.isNonNegative(\\customer_id\\\")\"</td>\n",
       "      <td>customer_id</td>\n",
       "      <td>ComplianceConstraint(Compliance('customer_id' has no negative values,customer_id &gt;= 0,None))</td>\n",
       "      <td>Minimum: 10229.0</td>\n",
       "      <td>'customer_id' has no negative values</td>\n",
       "      <td>If we see only non-negative numbers in a column, we suggest a corresponding constraint</td>\n",
       "      <td>NonNegativeNumbersRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.hasDataType(\\customer_id\\\", ConstrainableDataTypes.Integral)\"</td>\n",
       "      <td>customer_id</td>\n",
       "      <td>AnalysisBasedConstraint(DataType(customer_id,None),&lt;function1&gt;,Some(&lt;function1&gt;),None)</td>\n",
       "      <td>DataType: Integral</td>\n",
       "      <td>'customer_id' has type Integral</td>\n",
       "      <td>If we detect a non-string type, we suggest a type constraint</td>\n",
       "      <td>RetainTypeRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>.isComplete(\\review_date\\\")\"</td>\n",
       "      <td>review_date</td>\n",
       "      <td>CompletenessConstraint(Completeness(review_date,None))</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'review_date' is not null</td>\n",
       "      <td>If a column is complete in the sample, we suggest a NOT NULL constraint</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>.isComplete(\\helpful_votes\\\")\"</td>\n",
       "      <td>helpful_votes</td>\n",
       "      <td>CompletenessConstraint(Completeness(helpful_votes,None))</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'helpful_votes' is not null</td>\n",
       "      <td>If a column is complete in the sample, we suggest a NOT NULL constraint</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>.isNonNegative(\\helpful_votes\\\")\"</td>\n",
       "      <td>helpful_votes</td>\n",
       "      <td>ComplianceConstraint(Compliance('helpful_votes' has no negative values,helpful_votes &gt;= 0,None))</td>\n",
       "      <td>Minimum: 0.0</td>\n",
       "      <td>'helpful_votes' has no negative values</td>\n",
       "      <td>If we see only non-negative numbers in a column, we suggest a corresponding constraint</td>\n",
       "      <td>NonNegativeNumbersRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.isComplete(\\star_rating\\\")\"</td>\n",
       "      <td>star_rating</td>\n",
       "      <td>CompletenessConstraint(Completeness(star_rating,None))</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'star_rating' is not null</td>\n",
       "      <td>If a column is complete in the sample, we suggest a NOT NULL constraint</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>.isNonNegative(\\star_rating\\\")\"</td>\n",
       "      <td>star_rating</td>\n",
       "      <td>ComplianceConstraint(Compliance('star_rating' has no negative values,star_rating &gt;= 0,None))</td>\n",
       "      <td>Minimum: 1.0</td>\n",
       "      <td>'star_rating' has no negative values</td>\n",
       "      <td>If we see only non-negative numbers in a column, we suggest a corresponding constraint</td>\n",
       "      <td>NonNegativeNumbersRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>.isComplete(\\product_title\\\")\"</td>\n",
       "      <td>product_title</td>\n",
       "      <td>CompletenessConstraint(Completeness(product_title,None))</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'product_title' is not null</td>\n",
       "      <td>If a column is complete in the sample, we suggest a NOT NULL constraint</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>.isComplete(\\review_headline\\\")\"</td>\n",
       "      <td>review_headline</td>\n",
       "      <td>CompletenessConstraint(Completeness(review_headline,None))</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'review_headline' is not null</td>\n",
       "      <td>If a column is complete in the sample, we suggest a NOT NULL constraint</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>.isComplete(\\product_id\\\")\"</td>\n",
       "      <td>product_id</td>\n",
       "      <td>CompletenessConstraint(Completeness(product_id,None))</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'product_id' is not null</td>\n",
       "      <td>If a column is complete in the sample, we suggest a NOT NULL constraint</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>.isComplete(\\total_votes\\\")\"</td>\n",
       "      <td>total_votes</td>\n",
       "      <td>CompletenessConstraint(Completeness(total_votes,None))</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'total_votes' is not null</td>\n",
       "      <td>If a column is complete in the sample, we suggest a NOT NULL constraint</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>.isNonNegative(\\total_votes\\\")\"</td>\n",
       "      <td>total_votes</td>\n",
       "      <td>ComplianceConstraint(Compliance('total_votes' has no negative values,total_votes &gt;= 0,None))</td>\n",
       "      <td>Minimum: 0.0</td>\n",
       "      <td>'total_votes' has no negative values</td>\n",
       "      <td>If we see only non-negative numbers in a column, we suggest a corresponding constraint</td>\n",
       "      <td>NonNegativeNumbersRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>.isContainedIn(\\product_category\\\", [\\\"Gift Card\\\", \\\"Digital_Video_Games\\\", \\\"Digital_Software\\\"])\"</td>\n",
       "      <td>product_category</td>\n",
       "      <td>ComplianceConstraint(Compliance('product_category' has value range 'Gift Card', 'Digital_Video_Games', 'Digital_Software',`product_category` IN ('Gift Card', 'Digital_Video_Games', 'Digital_Software'),None))</td>\n",
       "      <td>Compliance: 1</td>\n",
       "      <td>'product_category' has value range 'Gift Card', 'Digital_Video_Games', 'Digital_Software'</td>\n",
       "      <td>If we see a categorical range for a column, we suggest an IS IN (...) constraint</td>\n",
       "      <td>CategoricalRangeRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>.isComplete(\\product_category\\\")\"</td>\n",
       "      <td>product_category</td>\n",
       "      <td>CompletenessConstraint(Completeness(product_category,None))</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'product_category' is not null</td>\n",
       "      <td>If a column is complete in the sample, we suggest a NOT NULL constraint</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>.isContainedIn(\\product_category\\\", [\\\"Gift Card\\\", \\\"Digital_Video_Games\\\", \\\"Digital_Software\\\"], lambda x: x &gt;= 0.99, \\\"It should be above 0.99!\\\")\"</td>\n",
       "      <td>product_category</td>\n",
       "      <td>ComplianceConstraint(Compliance('product_category' has value range 'Gift Card', 'Digital_Video_Games', 'Digital_Software' for at least 99.0% of values,`product_category` IN ('Gift Card', 'Digital_Video_Games', 'Digital_Software'),None))</td>\n",
       "      <td>Compliance: 0.9999999999999999</td>\n",
       "      <td>'product_category' has value range 'Gift Card', 'Digital_Video_Games', 'Digital_Software' for at least 99.0% of values</td>\n",
       "      <td>If we see a categorical range for most values in a column, we suggest an IS IN (...) constraint that should hold for most values</td>\n",
       "      <td>FractionalCategoricalRangeRule(0.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>.isComplete(\\product_parent\\\")\"</td>\n",
       "      <td>product_parent</td>\n",
       "      <td>CompletenessConstraint(Completeness(product_parent,None))</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'product_parent' is not null</td>\n",
       "      <td>If a column is complete in the sample, we suggest a NOT NULL constraint</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>.isNonNegative(\\product_parent\\\")\"</td>\n",
       "      <td>product_parent</td>\n",
       "      <td>ComplianceConstraint(Compliance('product_parent' has no negative values,product_parent &gt;= 0,None))</td>\n",
       "      <td>Minimum: 209709.0</td>\n",
       "      <td>'product_parent' has no negative values</td>\n",
       "      <td>If we see only non-negative numbers in a column, we suggest a corresponding constraint</td>\n",
       "      <td>NonNegativeNumbersRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>.hasDataType(\\product_parent\\\", ConstrainableDataTypes.Integral)\"</td>\n",
       "      <td>product_parent</td>\n",
       "      <td>AnalysisBasedConstraint(DataType(product_parent,None),&lt;function1&gt;,Some(&lt;function1&gt;),None)</td>\n",
       "      <td>DataType: Integral</td>\n",
       "      <td>'product_parent' has type Integral</td>\n",
       "      <td>If we detect a non-string type, we suggest a type constraint</td>\n",
       "      <td>RetainTypeRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>.hasCompleteness(\\review_body\\\", lambda x: x &gt;= 0.99, \\\"It should be above 0.99!\\\")\"</td>\n",
       "      <td>review_body</td>\n",
       "      <td>CompletenessConstraint(Completeness(review_body,None))</td>\n",
       "      <td>Completeness: 0.9999924357225524</td>\n",
       "      <td>'review_body' has less than 1% missing values</td>\n",
       "      <td>If a column is incomplete in the sample, we model its completeness as a binomial variable, estimate a confidence interval and use this to define a lower bound for the completeness</td>\n",
       "      <td>RetainCompletenessRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>.isContainedIn(\\vine\\\", [\\\"N\\\"])\"</td>\n",
       "      <td>vine</td>\n",
       "      <td>ComplianceConstraint(Compliance('vine' has value range 'N',`vine` IN ('N'),None))</td>\n",
       "      <td>Compliance: 1</td>\n",
       "      <td>'vine' has value range 'N'</td>\n",
       "      <td>If we see a categorical range for a column, we suggest an IS IN (...) constraint</td>\n",
       "      <td>CategoricalRangeRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>.isComplete(\\vine\\\")\"</td>\n",
       "      <td>vine</td>\n",
       "      <td>CompletenessConstraint(Completeness(vine,None))</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'vine' is not null</td>\n",
       "      <td>If a column is complete in the sample, we suggest a NOT NULL constraint</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>.isContainedIn(\\marketplace\\\", [\\\"US\\\"])\"</td>\n",
       "      <td>marketplace</td>\n",
       "      <td>ComplianceConstraint(Compliance('marketplace' has value range 'US',`marketplace` IN ('US'),None))</td>\n",
       "      <td>Compliance: 1</td>\n",
       "      <td>'marketplace' has value range 'US'</td>\n",
       "      <td>If we see a categorical range for a column, we suggest an IS IN (...) constraint</td>\n",
       "      <td>CategoricalRangeRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>.isComplete(\\marketplace\\\")\"</td>\n",
       "      <td>marketplace</td>\n",
       "      <td>CompletenessConstraint(Completeness(marketplace,None))</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'marketplace' is not null</td>\n",
       "      <td>If a column is complete in the sample, we suggest a NOT NULL constraint</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>.isContainedIn(\\verified_purchase\\\", [\\\"Y\\\", \\\"N\\\"])\"</td>\n",
       "      <td>verified_purchase</td>\n",
       "      <td>ComplianceConstraint(Compliance('verified_purchase' has value range 'Y', 'N',`verified_purchase` IN ('Y', 'N'),None))</td>\n",
       "      <td>Compliance: 1</td>\n",
       "      <td>'verified_purchase' has value range 'Y', 'N'</td>\n",
       "      <td>If we see a categorical range for a column, we suggest an IS IN (...) constraint</td>\n",
       "      <td>CategoricalRangeRule()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>.isComplete(\\verified_purchase\\\")\"</td>\n",
       "      <td>verified_purchase</td>\n",
       "      <td>CompletenessConstraint(Completeness(verified_purchase,None))</td>\n",
       "      <td>Completeness: 1.0</td>\n",
       "      <td>'verified_purchase' is not null</td>\n",
       "      <td>If a column is complete in the sample, we suggest a NOT NULL constraint</td>\n",
       "      <td>CompleteIfCompleteRule()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                        code_for_constraint  \\\n",
       "0                                                                                                                                .isComplete(\\review_id\\\")\"   \n",
       "1                                                                                                                                  .isUnique(\\review_id\\\")\"   \n",
       "2                                                                                                                              .isComplete(\\customer_id\\\")\"   \n",
       "3                                                                                                                           .isNonNegative(\\customer_id\\\")\"   \n",
       "4                                                                                            .hasDataType(\\customer_id\\\", ConstrainableDataTypes.Integral)\"   \n",
       "5                                                                                                                              .isComplete(\\review_date\\\")\"   \n",
       "6                                                                                                                            .isComplete(\\helpful_votes\\\")\"   \n",
       "7                                                                                                                         .isNonNegative(\\helpful_votes\\\")\"   \n",
       "8                                                                                                                              .isComplete(\\star_rating\\\")\"   \n",
       "9                                                                                                                           .isNonNegative(\\star_rating\\\")\"   \n",
       "10                                                                                                                           .isComplete(\\product_title\\\")\"   \n",
       "11                                                                                                                         .isComplete(\\review_headline\\\")\"   \n",
       "12                                                                                                                              .isComplete(\\product_id\\\")\"   \n",
       "13                                                                                                                             .isComplete(\\total_votes\\\")\"   \n",
       "14                                                                                                                          .isNonNegative(\\total_votes\\\")\"   \n",
       "15                                                     .isContainedIn(\\product_category\\\", [\\\"Gift Card\\\", \\\"Digital_Video_Games\\\", \\\"Digital_Software\\\"])\"   \n",
       "16                                                                                                                        .isComplete(\\product_category\\\")\"   \n",
       "17  .isContainedIn(\\product_category\\\", [\\\"Gift Card\\\", \\\"Digital_Video_Games\\\", \\\"Digital_Software\\\"], lambda x: x >= 0.99, \\\"It should be above 0.99!\\\")\"   \n",
       "18                                                                                                                          .isComplete(\\product_parent\\\")\"   \n",
       "19                                                                                                                       .isNonNegative(\\product_parent\\\")\"   \n",
       "20                                                                                        .hasDataType(\\product_parent\\\", ConstrainableDataTypes.Integral)\"   \n",
       "21                                                                     .hasCompleteness(\\review_body\\\", lambda x: x >= 0.99, \\\"It should be above 0.99!\\\")\"   \n",
       "22                                                                                                                        .isContainedIn(\\vine\\\", [\\\"N\\\"])\"   \n",
       "23                                                                                                                                    .isComplete(\\vine\\\")\"   \n",
       "24                                                                                                                .isContainedIn(\\marketplace\\\", [\\\"US\\\"])\"   \n",
       "25                                                                                                                             .isComplete(\\marketplace\\\")\"   \n",
       "26                                                                                                    .isContainedIn(\\verified_purchase\\\", [\\\"Y\\\", \\\"N\\\"])\"   \n",
       "27                                                                                                                       .isComplete(\\verified_purchase\\\")\"   \n",
       "\n",
       "          column_name  \\\n",
       "0           review_id   \n",
       "1           review_id   \n",
       "2         customer_id   \n",
       "3         customer_id   \n",
       "4         customer_id   \n",
       "5         review_date   \n",
       "6       helpful_votes   \n",
       "7       helpful_votes   \n",
       "8         star_rating   \n",
       "9         star_rating   \n",
       "10      product_title   \n",
       "11    review_headline   \n",
       "12         product_id   \n",
       "13        total_votes   \n",
       "14        total_votes   \n",
       "15   product_category   \n",
       "16   product_category   \n",
       "17   product_category   \n",
       "18     product_parent   \n",
       "19     product_parent   \n",
       "20     product_parent   \n",
       "21        review_body   \n",
       "22               vine   \n",
       "23               vine   \n",
       "24        marketplace   \n",
       "25        marketplace   \n",
       "26  verified_purchase   \n",
       "27  verified_purchase   \n",
       "\n",
       "                                                                                                                                                                                                                                 constraint_name  \\\n",
       "0                                                                                                                                                                                           CompletenessConstraint(Completeness(review_id,None))   \n",
       "1                                                                                                                                                                                         UniquenessConstraint(Uniqueness(List(review_id),None))   \n",
       "2                                                                                                                                                                                         CompletenessConstraint(Completeness(customer_id,None))   \n",
       "3                                                                                                                                                   ComplianceConstraint(Compliance('customer_id' has no negative values,customer_id >= 0,None))   \n",
       "4                                                                                                                                                         AnalysisBasedConstraint(DataType(customer_id,None),<function1>,Some(<function1>),None)   \n",
       "5                                                                                                                                                                                         CompletenessConstraint(Completeness(review_date,None))   \n",
       "6                                                                                                                                                                                       CompletenessConstraint(Completeness(helpful_votes,None))   \n",
       "7                                                                                                                                               ComplianceConstraint(Compliance('helpful_votes' has no negative values,helpful_votes >= 0,None))   \n",
       "8                                                                                                                                                                                         CompletenessConstraint(Completeness(star_rating,None))   \n",
       "9                                                                                                                                                   ComplianceConstraint(Compliance('star_rating' has no negative values,star_rating >= 0,None))   \n",
       "10                                                                                                                                                                                      CompletenessConstraint(Completeness(product_title,None))   \n",
       "11                                                                                                                                                                                    CompletenessConstraint(Completeness(review_headline,None))   \n",
       "12                                                                                                                                                                                         CompletenessConstraint(Completeness(product_id,None))   \n",
       "13                                                                                                                                                                                        CompletenessConstraint(Completeness(total_votes,None))   \n",
       "14                                                                                                                                                  ComplianceConstraint(Compliance('total_votes' has no negative values,total_votes >= 0,None))   \n",
       "15                               ComplianceConstraint(Compliance('product_category' has value range 'Gift Card', 'Digital_Video_Games', 'Digital_Software',`product_category` IN ('Gift Card', 'Digital_Video_Games', 'Digital_Software'),None))   \n",
       "16                                                                                                                                                                                   CompletenessConstraint(Completeness(product_category,None))   \n",
       "17  ComplianceConstraint(Compliance('product_category' has value range 'Gift Card', 'Digital_Video_Games', 'Digital_Software' for at least 99.0% of values,`product_category` IN ('Gift Card', 'Digital_Video_Games', 'Digital_Software'),None))   \n",
       "18                                                                                                                                                                                     CompletenessConstraint(Completeness(product_parent,None))   \n",
       "19                                                                                                                                            ComplianceConstraint(Compliance('product_parent' has no negative values,product_parent >= 0,None))   \n",
       "20                                                                                                                                                     AnalysisBasedConstraint(DataType(product_parent,None),<function1>,Some(<function1>),None)   \n",
       "21                                                                                                                                                                                        CompletenessConstraint(Completeness(review_body,None))   \n",
       "22                                                                                                                                                             ComplianceConstraint(Compliance('vine' has value range 'N',`vine` IN ('N'),None))   \n",
       "23                                                                                                                                                                                               CompletenessConstraint(Completeness(vine,None))   \n",
       "24                                                                                                                                             ComplianceConstraint(Compliance('marketplace' has value range 'US',`marketplace` IN ('US'),None))   \n",
       "25                                                                                                                                                                                        CompletenessConstraint(Completeness(marketplace,None))   \n",
       "26                                                                                                                         ComplianceConstraint(Compliance('verified_purchase' has value range 'Y', 'N',`verified_purchase` IN ('Y', 'N'),None))   \n",
       "27                                                                                                                                                                                  CompletenessConstraint(Completeness(verified_purchase,None))   \n",
       "\n",
       "                             current_value  \\\n",
       "0                        Completeness: 1.0   \n",
       "1   ApproxDistinctness: 0.9624383196209793   \n",
       "2                        Completeness: 1.0   \n",
       "3                         Minimum: 10229.0   \n",
       "4                       DataType: Integral   \n",
       "5                        Completeness: 1.0   \n",
       "6                        Completeness: 1.0   \n",
       "7                             Minimum: 0.0   \n",
       "8                        Completeness: 1.0   \n",
       "9                             Minimum: 1.0   \n",
       "10                       Completeness: 1.0   \n",
       "11                       Completeness: 1.0   \n",
       "12                       Completeness: 1.0   \n",
       "13                       Completeness: 1.0   \n",
       "14                            Minimum: 0.0   \n",
       "15                           Compliance: 1   \n",
       "16                       Completeness: 1.0   \n",
       "17          Compliance: 0.9999999999999999   \n",
       "18                       Completeness: 1.0   \n",
       "19                       Minimum: 209709.0   \n",
       "20                      DataType: Integral   \n",
       "21        Completeness: 0.9999924357225524   \n",
       "22                           Compliance: 1   \n",
       "23                       Completeness: 1.0   \n",
       "24                           Compliance: 1   \n",
       "25                       Completeness: 1.0   \n",
       "26                           Compliance: 1   \n",
       "27                       Completeness: 1.0   \n",
       "\n",
       "                                                                                                               description  \\\n",
       "0                                                                                                  'review_id' is not null   \n",
       "1                                                                                                    'review_id' is unique   \n",
       "2                                                                                                'customer_id' is not null   \n",
       "3                                                                                     'customer_id' has no negative values   \n",
       "4                                                                                          'customer_id' has type Integral   \n",
       "5                                                                                                'review_date' is not null   \n",
       "6                                                                                              'helpful_votes' is not null   \n",
       "7                                                                                   'helpful_votes' has no negative values   \n",
       "8                                                                                                'star_rating' is not null   \n",
       "9                                                                                     'star_rating' has no negative values   \n",
       "10                                                                                             'product_title' is not null   \n",
       "11                                                                                           'review_headline' is not null   \n",
       "12                                                                                                'product_id' is not null   \n",
       "13                                                                                               'total_votes' is not null   \n",
       "14                                                                                    'total_votes' has no negative values   \n",
       "15                               'product_category' has value range 'Gift Card', 'Digital_Video_Games', 'Digital_Software'   \n",
       "16                                                                                          'product_category' is not null   \n",
       "17  'product_category' has value range 'Gift Card', 'Digital_Video_Games', 'Digital_Software' for at least 99.0% of values   \n",
       "18                                                                                            'product_parent' is not null   \n",
       "19                                                                                 'product_parent' has no negative values   \n",
       "20                                                                                      'product_parent' has type Integral   \n",
       "21                                                                           'review_body' has less than 1% missing values   \n",
       "22                                                                                              'vine' has value range 'N'   \n",
       "23                                                                                                      'vine' is not null   \n",
       "24                                                                                      'marketplace' has value range 'US'   \n",
       "25                                                                                               'marketplace' is not null   \n",
       "26                                                                            'verified_purchase' has value range 'Y', 'N'   \n",
       "27                                                                                         'verified_purchase' is not null   \n",
       "\n",
       "                                                                                                                                                                       rule_description  \\\n",
       "0                                                                                                               If a column is complete in the sample, we suggest a NOT NULL constraint   \n",
       "1                    If the ratio of approximate num distinct values in a column is close to the number of records (within the error of the HLL sketch), we suggest a UNIQUE constraint   \n",
       "2                                                                                                               If a column is complete in the sample, we suggest a NOT NULL constraint   \n",
       "3                                                                                                If we see only non-negative numbers in a column, we suggest a corresponding constraint   \n",
       "4                                                                                                                          If we detect a non-string type, we suggest a type constraint   \n",
       "5                                                                                                               If a column is complete in the sample, we suggest a NOT NULL constraint   \n",
       "6                                                                                                               If a column is complete in the sample, we suggest a NOT NULL constraint   \n",
       "7                                                                                                If we see only non-negative numbers in a column, we suggest a corresponding constraint   \n",
       "8                                                                                                               If a column is complete in the sample, we suggest a NOT NULL constraint   \n",
       "9                                                                                                If we see only non-negative numbers in a column, we suggest a corresponding constraint   \n",
       "10                                                                                                              If a column is complete in the sample, we suggest a NOT NULL constraint   \n",
       "11                                                                                                              If a column is complete in the sample, we suggest a NOT NULL constraint   \n",
       "12                                                                                                              If a column is complete in the sample, we suggest a NOT NULL constraint   \n",
       "13                                                                                                              If a column is complete in the sample, we suggest a NOT NULL constraint   \n",
       "14                                                                                               If we see only non-negative numbers in a column, we suggest a corresponding constraint   \n",
       "15                                                                                                     If we see a categorical range for a column, we suggest an IS IN (...) constraint   \n",
       "16                                                                                                              If a column is complete in the sample, we suggest a NOT NULL constraint   \n",
       "17                                                     If we see a categorical range for most values in a column, we suggest an IS IN (...) constraint that should hold for most values   \n",
       "18                                                                                                              If a column is complete in the sample, we suggest a NOT NULL constraint   \n",
       "19                                                                                               If we see only non-negative numbers in a column, we suggest a corresponding constraint   \n",
       "20                                                                                                                         If we detect a non-string type, we suggest a type constraint   \n",
       "21  If a column is incomplete in the sample, we model its completeness as a binomial variable, estimate a confidence interval and use this to define a lower bound for the completeness   \n",
       "22                                                                                                     If we see a categorical range for a column, we suggest an IS IN (...) constraint   \n",
       "23                                                                                                              If a column is complete in the sample, we suggest a NOT NULL constraint   \n",
       "24                                                                                                     If we see a categorical range for a column, we suggest an IS IN (...) constraint   \n",
       "25                                                                                                              If a column is complete in the sample, we suggest a NOT NULL constraint   \n",
       "26                                                                                                     If we see a categorical range for a column, we suggest an IS IN (...) constraint   \n",
       "27                                                                                                              If a column is complete in the sample, we suggest a NOT NULL constraint   \n",
       "\n",
       "                        suggesting_rule  \n",
       "0              CompleteIfCompleteRule()  \n",
       "1     UniqueIfApproximatelyUniqueRule()  \n",
       "2              CompleteIfCompleteRule()  \n",
       "3              NonNegativeNumbersRule()  \n",
       "4                      RetainTypeRule()  \n",
       "5              CompleteIfCompleteRule()  \n",
       "6              CompleteIfCompleteRule()  \n",
       "7              NonNegativeNumbersRule()  \n",
       "8              CompleteIfCompleteRule()  \n",
       "9              NonNegativeNumbersRule()  \n",
       "10             CompleteIfCompleteRule()  \n",
       "11             CompleteIfCompleteRule()  \n",
       "12             CompleteIfCompleteRule()  \n",
       "13             CompleteIfCompleteRule()  \n",
       "14             NonNegativeNumbersRule()  \n",
       "15               CategoricalRangeRule()  \n",
       "16             CompleteIfCompleteRule()  \n",
       "17  FractionalCategoricalRangeRule(0.9)  \n",
       "18             CompleteIfCompleteRule()  \n",
       "19             NonNegativeNumbersRule()  \n",
       "20                     RetainTypeRule()  \n",
       "21             RetainCompletenessRule()  \n",
       "22               CategoricalRangeRule()  \n",
       "23             CompleteIfCompleteRule()  \n",
       "24               CategoricalRangeRule()  \n",
       "25             CompleteIfCompleteRule()  \n",
       "26               CategoricalRangeRule()  \n",
       "27             CompleteIfCompleteRule()  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_constraint_suggestions = load_dataset(path='./amazon-reviews-spark-analyzer/constraint-suggestions/', sep='\\t', header=0)\n",
    "\n",
    "pd.set_option('max_colwidth', 999)\n",
    "\n",
    "# df_constraint_suggestions = df_constraint_suggestions[['_1', '_2', '_3']].dropna()\n",
    "# df_constraint_suggestions.columns=['column_name', 'description', 'code']\n",
    "df_constraint_suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Release Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "\n",
    "try {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "    Jupyter.notebook.session.delete();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
